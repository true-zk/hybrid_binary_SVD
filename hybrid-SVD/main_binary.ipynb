{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Hybrid model for binary detect\n",
    "- load dataset\n",
    "- train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader as Dataloader_dsm\n",
    "from torch_geometric.loader import DataLoader as Dataloader_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from gendata_binary import gendata\n",
    "from gendata_binary import MyDataset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import degree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "CWE = 190"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data time span: 354.3098797798157\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of code text length: 209\n"
     ]
    }
   ],
   "source": [
    "# start load data\n",
    "time_start = time.time()\n",
    "\n",
    "dataset = gendata(CWE)\n",
    "random.shuffle(dataset)\n",
    "len_dataset = len(dataset)\n",
    "dataset_dsm = []\n",
    "dataset_dot = []\n",
    "for data in dataset:\n",
    "    dataset_dot.append(data[0])\n",
    "    dataset_dsm.append(data[1])\n",
    "print(\"load data time span:\", time.time() - time_start)\n",
    "\n",
    "dsm_height = []\n",
    "for data in dataset_dsm:\n",
    "    dsm_height.append(len(data['x']))\n",
    "plt.hist(dsm_height)\n",
    "plt.show()\n",
    "print(\"max of code text length:\", max(dsm_height))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "size_token = [130, 45]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset:6840,         len of train:4788,         len of validate:684,         len of test:1368\n"
     ]
    }
   ],
   "source": [
    "len_train = int(0.7 * len_dataset)\n",
    "len_test = int(0.2 * len_dataset)\n",
    "len_validate = len_dataset - len_train - len_test\n",
    "\n",
    "Train_dot_loader = Dataloader_dot(dataset_dot[:len_train], batch_size=32, shuffle=False, drop_last=True)\n",
    "Test_dot_loader = Dataloader_dot(dataset_dot[len_train: len_train+len_test], batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "Train_dsm_loader = Dataloader_dsm(MyDataset(dataset_dsm[:len_train], size_token), batch_size=32, shuffle=False, drop_last=True)\n",
    "Test_dsm_loader = Dataloader_dsm(MyDataset(dataset_dsm[len_train: len_train+len_test], size_token), batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "print(f\"len of dataset:{len_dataset}, \\\n",
    "        len of train:{len_train}, \\\n",
    "        len of validate:{len_validate}, \\\n",
    "        len of test:{len_test}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# GCN layer\n",
    "# cite: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super().__init__(aggr='add', **kwargs)  # \"Add\" aggregation (Step 5).\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x[N, in_channels]\n",
    "        # edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = self.lin(x)\n",
    "        row, col = edge_index\n",
    "\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        return  self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class HybridNet(torch.nn.Module):\n",
    "    def __init__(self, size0, size1):\n",
    "        super(HybridNet, self).__init__()\n",
    "        ###############################################################################\n",
    "        # GCN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "        ###############################################################################\n",
    "        self.conv1 = GCNConv(256, 256)\n",
    "        self.pool1 = TopKPooling(256, ratio=0.8)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.pool2 = TopKPooling(256, ratio=0.8)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.pool3 = TopKPooling(256, ratio=0.8)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.pool4 = TopKPooling(256, ratio=0.8)\n",
    "        self.conv5 = GCNConv(256, 256)\n",
    "        self.pool5 = TopKPooling(256, ratio=0.8)\n",
    "\n",
    "        self.convAtt1 = torch.nn.Conv1d(in_channels=512, out_channels=64, kernel_size=1, stride=2)\n",
    "        self.poolAtt1 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "        self.convAtt2 = torch.nn.Conv1d(64, 16, kernel_size=1, stride=2)\n",
    "        self.poolAtt2 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "        self.convAtt3 = torch.nn.Conv1d(16, 2, kernel_size=1, stride=2)\n",
    "        self.poolAtt3 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "        self.convAtt4 = torch.nn.Conv1d(2, 16, kernel_size=1, stride=2)\n",
    "        self.poolAtt4 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "        self.convAtt5 = torch.nn.Conv1d(16, 64, kernel_size=1, stride=2)\n",
    "        self.poolAtt5 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "        self.convAtt6 = torch.nn.Conv1d(64, 512, kernel_size=1, stride=2)\n",
    "        self.poolAtt6 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "        ###############################################################################\n",
    "        # textCNN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "        ###############################################################################\n",
    "        h_input = size0\n",
    "        w_input = size1\n",
    "        filter_list = [2, 4, 6, 8, 10, 12, 16, 20]\n",
    "        num_per_filter = 64\n",
    "        h_raw = [h_input - i + 1 for i in filter_list]  # 175-filter_size+1: after conv\n",
    "        filter_list1 = [math.ceil(i / 2) for i in h_raw]  # p = ceil[h_raw / 2]\n",
    "        self.num_filter = len(filter_list)\n",
    "        self.conv_t = nn.ModuleList([nn.Conv2d(1, num_per_filter, (cnv_size, w_input)) for cnv_size in filter_list])\n",
    "        self.max_t = nn.MaxPool2d(kernel_size=(num_per_filter, 1))\n",
    "        self.avg_t = nn.AvgPool2d(kernel_size=(num_per_filter, 1))\n",
    "        self.conv_t1 = nn.ModuleList([nn.Conv2d(2, 1, (cnv_size, 1), padding='same') for cnv_size in filter_list1])\n",
    "        self.sig = nn.Sigmoid()\n",
    "        h_res = sum(h_raw)  # textCNN_input_feature\n",
    "        self.lin0_ = torch.nn.Linear(h_res, 512)\n",
    "        ###############################################################################\n",
    "        # hybrid output   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "        ###############################################################################\n",
    "        # x: cfg 512  t:dsm 512\n",
    "        #=============================================================================#\n",
    "        # 方案1：只调比例 没有什么大用\n",
    "        ratio = 0.2\n",
    "        r_dot = round(ratio * 1024)\n",
    "        r_dsm = 1024 - r_dot\n",
    "        self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "        self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "        self.lin1_ = torch.nn.Linear(1024, 512)\n",
    "        self.lin2_ = torch.nn.Linear(512, 128)\n",
    "        self.lin3_ = torch.nn.Linear(128, 64)\n",
    "        self.lin4_ = torch.nn.Linear(64, 2)\n",
    "        self.dropout_ = nn.Dropout(0.6)\n",
    "\n",
    "        #=============================================================================#\n",
    "        # # 方案2：\n",
    "        # self.lin0x_ = torch.nn.Linear(512, 128)\n",
    "        # self.lin0t_ = torch.nn.Linear(512, 128)\n",
    "        #\n",
    "        # self.lin1x_ = torch.nn.Linear(128, 16)\n",
    "        # self.lin1t_ = torch.nn.Linear(128, 64)\n",
    "        #\n",
    "        # self.lin2x_ = torch.nn.Linear(80, 2)\n",
    "        # # self.lin2t_ = torch.nn.Linear(64, 2)\n",
    "        #\n",
    "        # self.dropoutx_ = nn.Dropout(0.6)\n",
    "        # self.dropoutt_ = nn.Dropout(0.6)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, t):\n",
    "        ###############################################################################\n",
    "        # GCN model :  x, edge_index, batch = data.x, data.edge_index, data.batch\t  #\n",
    "        ###############################################################################\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool4(x, edge_index, None, batch)\n",
    "        x4 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool5(x, edge_index, None, batch)\n",
    "        x5 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3 + x4 + x5\n",
    "\n",
    "        x = 1 / 5 * x\n",
    "\n",
    "        sx = x\n",
    "\n",
    "        x = x.unsqueeze(dim=2)\n",
    "\n",
    "        # attention\n",
    "        x = F.relu(self.convAtt1(x))\n",
    "        x = self.poolAtt1(x)\n",
    "        x = F.relu(self.convAtt2(x))\n",
    "        x = self.poolAtt2(x)\n",
    "        x = F.relu(self.convAtt3(x))\n",
    "        x = self.poolAtt3(x)\n",
    "\n",
    "        x = F.relu(self.convAtt4(x))\n",
    "        x = self.poolAtt4(x)\n",
    "        x = F.relu(self.convAtt5(x))\n",
    "        x = self.poolAtt5(x)\n",
    "        x = F.relu(self.convAtt6(x))\n",
    "        x = self.poolAtt6(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x = (x + 1) * sx\n",
    "\n",
    "        ###############################################################################\n",
    "        # TextCNN model :  t = batch * h * w\t\t\t\t\t\t\t\t\t\t  #\n",
    "        ###############################################################################\n",
    "\n",
    "        t = torch.unsqueeze(t, 1)  # batch, channel_in=1 , h, w\n",
    "        t = [torch.squeeze(F.relu(conv(t)), 3) for conv in self.conv_t]  # each_filter: batch, channel_out=64, h'\n",
    "        # t: num_filter * batch * num_per_filter=64 * h'\n",
    "\n",
    "        # attention\n",
    "        t = [torch.unsqueeze(i, 1) for i in t]  # num_filter * [ batch * 1 * num_per_filter=64 * h' ]\n",
    "\n",
    "        max_ = [self.max_t(i) for i in t]  # num_filter * [batch * 1 * 1 * h' ]\n",
    "        max_ = [torch.unsqueeze(torch.squeeze(i, 1), 3) for i in max_]  # num_filter * [batch * 1 * h' * 1]\n",
    "        avg_ = [self.avg_t(i) for i in t]  # num_filter * [batch * 1 * 1 * h' ]\n",
    "        avg_ = [torch.unsqueeze(torch.squeeze(i, 1), 3) for i in avg_]  # num_filter * [batch * 1 * h' * 1]\n",
    "\n",
    "        attention = [torch.cat((max_[i], avg_[i]), dim=1) for i in range(0, self.num_filter)]  # num_filter * [batch * 2 * h' * 1]\n",
    "        attention = [self.sig(self.conv_t1[i](attention[i])) for i in range(0, self.num_filter)]  # num_filter * [batch * 1 * h' * 1]\n",
    "        attention = [torch.unsqueeze(torch.squeeze(i, 3), 1) for i in attention]  # num_filter * [batch * 1 * 1 * h']\n",
    "\n",
    "        t = [t[i] * attention[i] for i in range(0, self.num_filter)]  # num_filter * [ batch * 1 * num_per_filter=64 * h' ]\n",
    "        t = [torch.squeeze(self.max_t(i)) for i in t]  # num_filter * [batch * h']\n",
    "        t = torch.cat(t, dim=1)  # batch * Σ(h')\n",
    "        t = torch.squeeze(t)\n",
    "        t = F.relu(self.lin0_(t))\n",
    "\n",
    "        ###############################################################################\n",
    "        # hybrid output :  #\n",
    "        ###############################################################################\n",
    "        # out layer\n",
    "        # x = F.relu(self.lin0x_(x))\n",
    "        # t = F.relu(self.lin0t_(t))\n",
    "        #\n",
    "        # x = self.dropoutx_(x)\n",
    "        # t = self.dropoutt_(t)\n",
    "        #\n",
    "        # x = F.relu(self.lin1x_(x))\n",
    "        # t = F.relu(self.lin1t_(t))\n",
    "        #\n",
    "        # x = torch.cat((t, x), dim=1)\n",
    "        #\n",
    "        # x = F.log_softmax(self.lin2x_(x), dim=-1)\n",
    "        x = F.relu(self.lin0x_(x))\n",
    "        t = F.relu(self.lin0t_(t))\n",
    "        x = torch.cat((t,x), dim=1)\n",
    "        x = F.relu(self.lin1_(x))\n",
    "        x = F.relu(self.lin2_(x))\n",
    "        x = self.dropout_(x)\n",
    "        x = F.relu(self.lin3_(x))\n",
    "        x = F.log_softmax(self.lin4_(x), dim=-1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = HybridNet(size_token[0], size_token[1]).to(device)\n",
    "model = HybridNet(size_token[0], size_token[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    iter_loader = iter(Train_dsm_loader)\n",
    "    for data in Train_dot_loader:\n",
    "        t, yy = next(iter_loader)\n",
    "        t = t.to(device)\n",
    "\n",
    "        data = data.to(device)\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, edge_index, batch, t)\n",
    "\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(Train_dot_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def test(loader0, loader1):\n",
    "    # loader0:dot loader1:dsm\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    pred_good = 0\n",
    "    pred_bad = 0\n",
    "    iter_loader = iter(loader1)\n",
    "    for data0 in loader0:\n",
    "        t, yy = next(iter_loader)\n",
    "        t = t.to(device)\n",
    "\n",
    "        data0 = data0.to(device)\n",
    "        x, edge_index, batch = data0.x, data0.edge_index, data0.batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x, edge_index, batch, t)\n",
    "        y_pred = y_pred.max(dim=1)[1]\n",
    "        correct += y_pred.eq(data0.y).sum().item()\n",
    "        for j in range(len(y_pred)):\n",
    "            if y_pred[j] == 0 and data0.y[j] == 0:\n",
    "                tp += 1\n",
    "                pred_bad += 1\n",
    "            elif y_pred[j] == 0 and data0.y[j] == 1:\n",
    "                fp += 1\n",
    "                pred_bad += 1\n",
    "            elif y_pred[j] == 1 and data0.y[j] == 0:\n",
    "                fn += 1\n",
    "                pred_good += 1\n",
    "            elif y_pred[j] == 1 and data0.y[j] == 1:\n",
    "                tn += 1\n",
    "                pred_good += 1\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return round(acc, 6), tp, fp, tn, fn, pred_good, pred_bad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Miniconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:883.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.28790, Train Acc: 0.98133,Test Acc: 0.97470, TP: 622, FP: 18, TN: 688, FN: 16, Pred_good: 0704, Pred_bad: 0640\n",
      "Epoch: 004, Loss: 0.00615, Train Acc: 1.00000,Test Acc: 1.00000, TP: 638, FP: 00, TN: 706, FN: 00, Pred_good: 0706, Pred_bad: 0638\n",
      "Epoch: 008, Loss: 0.00002, Train Acc: 1.00000,Test Acc: 1.00000, TP: 638, FP: 00, TN: 706, FN: 00, Pred_good: 0706, Pred_bad: 0638\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m best_acc_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m200\u001B[39m):\n\u001B[1;32m---> 10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     12\u001B[0m         train_acc, tp, fp, tn, fn, pred_good, pred_bad \u001B[38;5;241m=\u001B[39m test(Train_dot_loader, Train_dsm_loader)\n",
      "Cell \u001B[1;32mIn[9], line 17\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     15\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mnll_loss(output, data\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m     16\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 17\u001B[0m     loss_all \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mnum_graphs \u001B[38;5;241m*\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss_all \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(Train_dot_loader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# train & test\n",
    "# time log\n",
    "time_start = time.time()\n",
    "\n",
    "train_loss_a = np.zeros(200)\n",
    "test_acc_a = np.zeros(200)\n",
    "best_acc = 0\n",
    "best_acc_model = None\n",
    "for epoch in range(0, 200):\n",
    "    loss = train(epoch)\n",
    "    if epoch % 4 == 0:\n",
    "        train_acc, tp, fp, tn, fn, pred_good, pred_bad = test(Train_dot_loader, Train_dsm_loader)\n",
    "        test_acc, tp, fp, tn, fn, pred_good, pred_bad = test(Test_dot_loader, Test_dsm_loader)\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_acc_model = model\n",
    "        train_loss_a[epoch] = loss\n",
    "        test_acc_a[epoch] = test_acc\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}, Train Acc: {:.5f},Test Acc: {:.5f}, TP: {:02d}, FP: {:02d}, TN: {:02d}, FN: {:02d}, Pred_good: {:04d}, Pred_bad: {:04d}'.\n",
    "            format(epoch, loss, train_acc, test_acc, tp, fp, tn, fn, pred_good, pred_bad))\n",
    "\n",
    "# fin train & test;;print time span\n",
    "time_fin_train = time.time()\n",
    "print(\"train & test time span : \", time_fin_train - time_start)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the best test acc model\n",
    "path_out_model = r'D:\\Desktop\\hybrid-SVD\\model_out\\CWE127.model'\n",
    "model = model.to('cpu')\n",
    "torch.save(model, path_out_model)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(0, 200, 1)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"train loss\")\n",
    "plt.plot(x, train_loss_a[0:200])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(0, 200, 1)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"test acc\")\n",
    "plt.plot(x, test_acc_a[0:200])\n",
    "\n",
    "print(\"Best acc:\", best_acc)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

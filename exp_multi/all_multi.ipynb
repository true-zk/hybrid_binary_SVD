{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### All three models for multiple detect Compare\n",
    "- load dataset\n",
    "- train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader as Dataloader_dsm, Dataset\n",
    "from torch_geometric.loader import DataLoader as Dataloader_dot\n",
    "from torch_geometric.nn import MessagePassing, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# GCN layer\n",
    "# cite: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super().__init__(aggr='add', **kwargs)  # \"Add\" aggregation (Step 5).\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x[N, in_channels]\n",
    "        # edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = self.lin(x)\n",
    "        row, col = edge_index\n",
    "\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        return  self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class HybridNet(torch.nn.Module):\n",
    "\tdef __init__(self, size0, size1):\n",
    "\t\tsuper(HybridNet, self).__init__()\n",
    "\t\t###############################################################################\n",
    "\t\t# GCN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\tself.conv1 = GCNConv(256, 256)\n",
    "\t\tself.pool1 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv2 = GCNConv(256, 256)\n",
    "\t\tself.pool2 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv3 = GCNConv(256, 256)\n",
    "\t\tself.pool3 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv4 = GCNConv(256, 256)\n",
    "\t\tself.pool4 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv5 = GCNConv(256, 256)\n",
    "\t\tself.pool5 = TopKPooling(256, ratio=0.8)\n",
    "\n",
    "\t\tself.convAtt1 = torch.nn.Conv1d(in_channels=512, out_channels=64, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt1 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt2 = torch.nn.Conv1d(64, 16, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt2 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt3 = torch.nn.Conv1d(16, 2, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt3 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "\t\tself.convAtt4 = torch.nn.Conv1d(2, 16, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt4 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt5 = torch.nn.Conv1d(16, 64, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt5 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt6 = torch.nn.Conv1d(64, 512, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt6 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "\t\t###############################################################################\n",
    "\t\t# textCNN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\th_input = size0\n",
    "\t\tw_input = size1\n",
    "\t\tfilter_list = [2, 4, 6, 8, 10, 12, 16, 20]\n",
    "\t\tnum_per_filter = 64\n",
    "\t\th_raw = [h_input - i + 1 for i in filter_list]  # 175-filter_size+1: after conv\n",
    "\t\tfilter_list1 = [math.ceil(i / 2) for i in h_raw]  # p = ceil[h_raw / 2]\n",
    "\t\tself.num_filter = len(filter_list)\n",
    "\t\tself.conv_t = nn.ModuleList([nn.Conv2d(1, num_per_filter, (cnv_size, w_input)) for cnv_size in filter_list])\n",
    "\t\tself.max_t = nn.MaxPool2d(kernel_size=(num_per_filter, 1))\n",
    "\t\tself.avg_t = nn.AvgPool2d(kernel_size=(num_per_filter, 1))\n",
    "\t\tself.conv_t1 = nn.ModuleList([nn.Conv2d(2, 1, (cnv_size, 1), padding='same') for cnv_size in filter_list1])\n",
    "\t\tself.sig = nn.Sigmoid()\n",
    "\t\th_res = sum(h_raw)  # textCNN_input_feature\n",
    "\t\tself.lin0_ = torch.nn.Linear(h_res, 512)\n",
    "\t\t###############################################################################\n",
    "\t\t# hybrid output   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# x: cfg  t:dsm\n",
    "\t\t# self.ratio = 0.5\n",
    "\t\t# r_dot = round(self.ratio * 1024)\n",
    "\t\t# r_dsm = 1024 - r_dot\n",
    "        #\n",
    "\t\t# self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "\t\t# self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "\n",
    "\t\tself.lin1_ = torch.nn.Linear(1024, 512)\n",
    "\t\tself.lin2_ = torch.nn.Linear(512, 128)\n",
    "\t\tself.lin3_ = torch.nn.Linear(128, 64)\n",
    "\t\tself.lin4_ = torch.nn.Linear(64, 6)\n",
    "\t\tself.dropout_ = nn.Dropout(0.6)\n",
    "\n",
    "\tdef forward(self, x, edge_index, batch, t):\n",
    "\t\t###############################################################################\n",
    "\t\t# GCN model :  x, edge_index, batch = data.x, data.edge_index, data.batch\t  #\n",
    "\t\t###############################################################################\n",
    "\t\tx = F.relu(self.conv1(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "\t\tx1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv2(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "\t\tx2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv3(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "\t\tx3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv4(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool4(x, edge_index, None, batch)\n",
    "\t\tx4 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv5(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool5(x, edge_index, None, batch)\n",
    "\t\tx5 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = x1 + x2 + x3 + x4 + x5\n",
    "\n",
    "\t\tx = 1 / 5 * x\n",
    "\n",
    "\t\tsx = x\n",
    "\n",
    "\t\tx = x.unsqueeze(dim=2)\n",
    "\n",
    "\t\t# attention\n",
    "\t\tx = F.relu(self.convAtt1(x))\n",
    "\t\tx = self.poolAtt1(x)\n",
    "\t\tx = F.relu(self.convAtt2(x))\n",
    "\t\tx = self.poolAtt2(x)\n",
    "\t\tx = F.relu(self.convAtt3(x))\n",
    "\t\tx = self.poolAtt3(x)\n",
    "\n",
    "\t\tx = F.relu(self.convAtt4(x))\n",
    "\t\tx = self.poolAtt4(x)\n",
    "\t\tx = F.relu(self.convAtt5(x))\n",
    "\t\tx = self.poolAtt5(x)\n",
    "\t\tx = F.relu(self.convAtt6(x))\n",
    "\t\tx = self.poolAtt6(x)\n",
    "\t\tx = x.squeeze()\n",
    "\n",
    "\t\tx = (x + 1) * sx\n",
    "\n",
    "\t\t###############################################################################\n",
    "\t\t# TextCNN model :  t = batch * h * w\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\tt = torch.unsqueeze(t, 1)\n",
    "\t\tt = [torch.squeeze(F.relu(conv(t)), 3) for conv in self.conv_t]\n",
    "\t\t# per_filter * [batch * num_per_filter * h_raw]\n",
    "\n",
    "\t\tfor i in range(0, self.num_filter):\n",
    "\t\t\tt[i] = torch.unsqueeze(t[i], 1)\n",
    "\t\t\t# [batch * 1 * num_per_filter * h_raw]\n",
    "\t\t\tmax_ = torch.unsqueeze(torch.squeeze(self.max_t(t[i]), 1), 3)\n",
    "\t\t\tavg_ = torch.unsqueeze(torch.squeeze(self.avg_t(t[i]), 1), 3)\n",
    "\n",
    "\t\t\tattention_ = torch.cat((max_, avg_), dim=1)\n",
    "\t\t\tattention_ = self.sig(self.conv_t1[i](attention_))\n",
    "\t\t\tattention_ = torch.unsqueeze(torch.squeeze(attention_, 3), 1)\n",
    "\t\t\tt[i] = t[i] * attention_\n",
    "\t\t\tt[i] = torch.squeeze(self.max_t(t[i]))\n",
    "\t\tt = torch.cat(t, dim=1)\n",
    "\t\tt = torch.squeeze(t)\n",
    "\t\tt = F.relu(self.lin0_(t))\n",
    "\t\t###############################################################################\n",
    "\t\t# hybrid output :  #\n",
    "\t\t###############################################################################\n",
    "\t\t# out layer\n",
    "\t\t# self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "\t\t# self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "        # if self.ratio != 0.5:\n",
    "\t\t#   x = F.relu(self.lin0x_(x))\n",
    "\t\t#   t = F.relu(self.lin0t_(t))\n",
    "\n",
    "\t\tx = torch.cat((x, t), dim=1)  # 512 + 512\n",
    "\n",
    "\t\tx = F.relu(self.lin1_(x))\n",
    "\t\tx = F.relu(self.lin2_(x))\n",
    "\t\tx = F.relu(self.lin3_(x))\n",
    "\t\tx = F.dropout(x, p=0.5, training=self.training)\n",
    "\t\tx = F.log_softmax(self.lin4_(x), dim=-1)\n",
    "\n",
    "\t\treturn x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CFGNet(torch.nn.Module):\n",
    "\tdef __init__(self, size0, size1):\n",
    "\t\tsuper(CFGNet, self).__init__()\n",
    "\t\t###############################################################################\n",
    "\t\t# GCN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\tself.conv1 = GCNConv(256, 256)\n",
    "\t\tself.pool1 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv2 = GCNConv(256, 256)\n",
    "\t\tself.pool2 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv3 = GCNConv(256, 256)\n",
    "\t\tself.pool3 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv4 = GCNConv(256, 256)\n",
    "\t\tself.pool4 = TopKPooling(256, ratio=0.8)\n",
    "\t\tself.conv5 = GCNConv(256, 256)\n",
    "\t\tself.pool5 = TopKPooling(256, ratio=0.8)\n",
    "\n",
    "\t\tself.convAtt1 = torch.nn.Conv1d(in_channels=512, out_channels=64, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt1 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt2 = torch.nn.Conv1d(64, 16, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt2 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt3 = torch.nn.Conv1d(16, 2, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt3 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "\t\tself.convAtt4 = torch.nn.Conv1d(2, 16, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt4 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt5 = torch.nn.Conv1d(16, 64, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt5 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\tself.convAtt6 = torch.nn.Conv1d(64, 512, kernel_size=1, stride=2)\n",
    "\t\tself.poolAtt6 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "\t\t###############################################################################\n",
    "\t\t# textCNN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# h_input = size0\n",
    "\t\t# w_input = size1\n",
    "\t\t# filter_list = [2, 4, 6, 8, 10, 12, 16, 20]\n",
    "\t\t# num_per_filter = 64\n",
    "\t\t# h_raw = [h_input - i + 1 for i in filter_list]  # 175-filter_size+1: after conv\n",
    "\t\t# filter_list1 = [math.ceil(i / 2) for i in h_raw]  # p = ceil[h_raw / 2]\n",
    "\t\t# self.num_filter = len(filter_list)\n",
    "\t\t# self.conv_t = nn.ModuleList([nn.Conv2d(1, num_per_filter, (cnv_size, w_input)) for cnv_size in filter_list])\n",
    "\t\t# self.max_t = nn.MaxPool2d(kernel_size=(num_per_filter, 1))\n",
    "\t\t# self.avg_t = nn.AvgPool2d(kernel_size=(num_per_filter, 1))\n",
    "\t\t# self.conv_t1 = nn.ModuleList([nn.Conv2d(2, 1, (cnv_size, 1), padding='same') for cnv_size in filter_list1])\n",
    "\t\t# self.sig = nn.Sigmoid()\n",
    "\t\t# h_res = sum(h_raw)  # textCNN_input_feature\n",
    "\t\t# self.lin0_ = torch.nn.Linear(h_res, 512)\n",
    "\t\t###############################################################################\n",
    "\t\t# hybrid output   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# x: cfg  t:dsm\n",
    "\t\t# self.ratio = 0.5\n",
    "\t\t# r_dot = round(self.ratio * 1024)\n",
    "\t\t# r_dsm = 1024 - r_dot\n",
    "        #\n",
    "\t\t# self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "\t\t# self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "\n",
    "\t\t# self.lin1_ = torch.nn.Linear(1024, 512)\n",
    "\t\tself.lin2_ = torch.nn.Linear(512, 128)\n",
    "\t\tself.lin3_ = torch.nn.Linear(128, 64)\n",
    "\t\tself.lin4_ = torch.nn.Linear(64, 6)\n",
    "\t\tself.dropout_ = nn.Dropout(0.6)\n",
    "\n",
    "\tdef forward(self, x, edge_index, batch, t):\n",
    "\t\t###############################################################################\n",
    "\t\t# GCN model :  x, edge_index, batch = data.x, data.edge_index, data.batch\t  #\n",
    "\t\t###############################################################################\n",
    "\t\tx = F.relu(self.conv1(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "\t\tx1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv2(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "\t\tx2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv3(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "\t\tx3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv4(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool4(x, edge_index, None, batch)\n",
    "\t\tx4 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = F.relu(self.conv5(x, edge_index))\n",
    "\t\tx, edge_index, _, batch, _, _ = self.pool5(x, edge_index, None, batch)\n",
    "\t\tx5 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "\t\tx = x1 + x2 + x3 + x4 + x5\n",
    "\n",
    "\t\tx = 1 / 5 * x\n",
    "\n",
    "\t\tsx = x\n",
    "\n",
    "\t\tx = x.unsqueeze(dim=2)\n",
    "\n",
    "\t\t# attention\n",
    "\t\tx = F.relu(self.convAtt1(x))\n",
    "\t\tx = self.poolAtt1(x)\n",
    "\t\tx = F.relu(self.convAtt2(x))\n",
    "\t\tx = self.poolAtt2(x)\n",
    "\t\tx = F.relu(self.convAtt3(x))\n",
    "\t\tx = self.poolAtt3(x)\n",
    "\n",
    "\t\tx = F.relu(self.convAtt4(x))\n",
    "\t\tx = self.poolAtt4(x)\n",
    "\t\tx = F.relu(self.convAtt5(x))\n",
    "\t\tx = self.poolAtt5(x)\n",
    "\t\tx = F.relu(self.convAtt6(x))\n",
    "\t\tx = self.poolAtt6(x)\n",
    "\t\tx = x.squeeze()\n",
    "\n",
    "\t\tx = (x + 1) * sx\n",
    "\n",
    "\t\t###############################################################################\n",
    "\t\t# TextCNN model :  t = batch * h * w\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# t = torch.unsqueeze(t, 1)\n",
    "\t\t# t = [torch.squeeze(F.relu(conv(t)), 3) for conv in self.conv_t]\n",
    "\t\t# # per_filter * [batch * num_per_filter * h_raw]\n",
    "\t\t#\n",
    "\t\t# for i in range(0, self.num_filter):\n",
    "\t\t# \tt[i] = torch.unsqueeze(t[i], 1)\n",
    "\t\t# \t# [batch * 1 * num_per_filter * h_raw]\n",
    "\t\t# \tmax_ = torch.unsqueeze(torch.squeeze(self.max_t(t[i]), 1), 3)\n",
    "\t\t# \tavg_ = torch.unsqueeze(torch.squeeze(self.avg_t(t[i]), 1), 3)\n",
    "\t\t#\n",
    "\t\t# \tattention_ = torch.cat((max_, avg_), dim=1)\n",
    "\t\t# \tattention_ = self.sig(self.conv_t1[i](attention_))\n",
    "\t\t# \tattention_ = torch.unsqueeze(torch.squeeze(attention_, 3), 1)\n",
    "\t\t# \tt[i] = t[i] * attention_\n",
    "\t\t# \tt[i] = torch.squeeze(self.max_t(t[i]))\n",
    "\t\t# t = torch.cat(t, dim=1)\n",
    "\t\t# t = torch.squeeze(t)\n",
    "\t\t# t = F.relu(self.lin0_(t))\n",
    "\t\t###############################################################################\n",
    "\t\t# hybrid output :  #\n",
    "\t\t###############################################################################\n",
    "\t\t# out layer\n",
    "\t\t# self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "\t\t# self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "        # if self.ratio != 0.5:\n",
    "\t\t#   x = F.relu(self.lin0x_(x))\n",
    "\t\t#   t = F.relu(self.lin0t_(t))\n",
    "\n",
    "\t\t# x = torch.cat((x, t), dim=1)  # 512 + 512\n",
    "\n",
    "\t\t# x = F.relu(self.lin1_(x))\n",
    "\t\tx = F.relu(self.lin2_(x))\n",
    "\t\tx = F.relu(self.lin3_(x))\n",
    "\t\tx = F.dropout(x, p=0.5, training=self.training)\n",
    "\t\tx = F.log_softmax(self.lin4_(x), dim=-1)\n",
    "\n",
    "\t\treturn x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TokenNet(torch.nn.Module):\n",
    "\tdef __init__(self, size0, size1):\n",
    "\t\tsuper(TokenNet, self).__init__()\n",
    "\t\t###############################################################################\n",
    "\t\t# GCN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# self.conv1 = GCNConv(256, 256)\n",
    "\t\t# self.pool1 = TopKPooling(256, ratio=0.8)\n",
    "\t\t# self.conv2 = GCNConv(256, 256)\n",
    "\t\t# self.pool2 = TopKPooling(256, ratio=0.8)\n",
    "\t\t# self.conv3 = GCNConv(256, 256)\n",
    "\t\t# self.pool3 = TopKPooling(256, ratio=0.8)\n",
    "\t\t# self.conv4 = GCNConv(256, 256)\n",
    "\t\t# self.pool4 = TopKPooling(256, ratio=0.8)\n",
    "\t\t# self.conv5 = GCNConv(256, 256)\n",
    "\t\t# self.pool5 = TopKPooling(256, ratio=0.8)\n",
    "\t\t#\n",
    "\t\t# self.convAtt1 = torch.nn.Conv1d(in_channels=512, out_channels=64, kernel_size=1, stride=2)\n",
    "\t\t# self.poolAtt1 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\t# self.convAtt2 = torch.nn.Conv1d(64, 16, kernel_size=1, stride=2)\n",
    "\t\t# self.poolAtt2 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\t# self.convAtt3 = torch.nn.Conv1d(16, 2, kernel_size=1, stride=2)\n",
    "\t\t# self.poolAtt3 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\t#\n",
    "\t\t# self.convAtt4 = torch.nn.Conv1d(2, 16, kernel_size=1, stride=2)\n",
    "\t\t# self.poolAtt4 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\t# self.convAtt5 = torch.nn.Conv1d(16, 64, kernel_size=1, stride=2)\n",
    "\t\t# self.poolAtt5 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\t\t# self.convAtt6 = torch.nn.Conv1d(64, 512, kernel_size=1, stride=2)\n",
    "\t\t# self.poolAtt6 = torch.nn.MaxPool1d(kernel_size=1, stride=2)\n",
    "\n",
    "\t\t###############################################################################\n",
    "\t\t# textCNN model   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\th_input = size0\n",
    "\t\tw_input = size1\n",
    "\t\tfilter_list = [2, 4, 6, 8, 10, 12, 16, 20]\n",
    "\t\tnum_per_filter = 64\n",
    "\t\th_raw = [h_input - i + 1 for i in filter_list]  # 175-filter_size+1: after conv\n",
    "\t\tfilter_list1 = [math.ceil(i / 2) for i in h_raw]  # p = ceil[h_raw / 2]\n",
    "\t\tself.num_filter = len(filter_list)\n",
    "\t\tself.conv_t = nn.ModuleList([nn.Conv2d(1, num_per_filter, (cnv_size, w_input)) for cnv_size in filter_list])\n",
    "\t\tself.max_t = nn.MaxPool2d(kernel_size=(num_per_filter, 1))\n",
    "\t\tself.avg_t = nn.AvgPool2d(kernel_size=(num_per_filter, 1))\n",
    "\t\tself.conv_t1 = nn.ModuleList([nn.Conv2d(2, 1, (cnv_size, 1), padding='same') for cnv_size in filter_list1])\n",
    "\t\tself.sig = nn.Sigmoid()\n",
    "\t\th_res = sum(h_raw)  # textCNN_input_feature\n",
    "\t\tself.lin0_ = torch.nn.Linear(h_res, 512)\n",
    "\t\t###############################################################################\n",
    "\t\t# hybrid output   \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# x: cfg  t:dsm\n",
    "\t\t# self.ratio = 0.5\n",
    "\t\t# r_dot = round(self.ratio * 1024)\n",
    "\t\t# r_dsm = 1024 - r_dot\n",
    "        #\n",
    "\t\t# self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "\t\t# self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "\n",
    "\t\t# self.lin1_ = torch.nn.Linear(1024, 512)\n",
    "\t\tself.lin2_ = torch.nn.Linear(512, 128)\n",
    "\t\tself.lin3_ = torch.nn.Linear(128, 64)\n",
    "\t\tself.lin4_ = torch.nn.Linear(64, 6)\n",
    "\t\tself.dropout_ = nn.Dropout(0.6)\n",
    "\n",
    "\tdef forward(self, x, edge_index, batch, t):\n",
    "\t\t###############################################################################\n",
    "\t\t# GCN model :  x, edge_index, batch = data.x, data.edge_index, data.batch\t  #\n",
    "\t\t###############################################################################\n",
    "\t\t# x = F.relu(self.conv1(x, edge_index))\n",
    "\t\t# x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "\t\t# x1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\t\t#\n",
    "\t\t# x = F.relu(self.conv2(x, edge_index))\n",
    "\t\t# x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "\t\t# x2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\t\t#\n",
    "\t\t# x = F.relu(self.conv3(x, edge_index))\n",
    "\t\t# x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "\t\t# x3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\t\t#\n",
    "\t\t# x = F.relu(self.conv4(x, edge_index))\n",
    "\t\t# x, edge_index, _, batch, _, _ = self.pool4(x, edge_index, None, batch)\n",
    "\t\t# x4 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\t\t#\n",
    "\t\t# x = F.relu(self.conv5(x, edge_index))\n",
    "\t\t# x, edge_index, _, batch, _, _ = self.pool5(x, edge_index, None, batch)\n",
    "\t\t# x5 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\t\t#\n",
    "\t\t# x = x1 + x2 + x3 + x4 + x5\n",
    "\t\t#\n",
    "\t\t# x = 1 / 5 * x\n",
    "\t\t#\n",
    "\t\t# sx = x\n",
    "\t\t#\n",
    "\t\t# x = x.unsqueeze(dim=2)\n",
    "\t\t#\n",
    "\t\t# # attention\n",
    "\t\t# x = F.relu(self.convAtt1(x))\n",
    "\t\t# x = self.poolAtt1(x)\n",
    "\t\t# x = F.relu(self.convAtt2(x))\n",
    "\t\t# x = self.poolAtt2(x)\n",
    "\t\t# x = F.relu(self.convAtt3(x))\n",
    "\t\t# x = self.poolAtt3(x)\n",
    "\t\t#\n",
    "\t\t# x = F.relu(self.convAtt4(x))\n",
    "\t\t# x = self.poolAtt4(x)\n",
    "\t\t# x = F.relu(self.convAtt5(x))\n",
    "\t\t# x = self.poolAtt5(x)\n",
    "\t\t# x = F.relu(self.convAtt6(x))\n",
    "\t\t# x = self.poolAtt6(x)\n",
    "\t\t# x = x.squeeze()\n",
    "\t\t#\n",
    "\t\t# x = (x + 1) * sx\n",
    "\n",
    "\t\t###############################################################################\n",
    "\t\t# TextCNN model :  t = batch * h * w\t\t\t\t\t\t\t\t\t\t  #\n",
    "\t\t###############################################################################\n",
    "\t\tt = torch.unsqueeze(t, 1)\n",
    "\t\tt = [torch.squeeze(F.relu(conv(t)), 3) for conv in self.conv_t]\n",
    "\t\t# per_filter * [batch * num_per_filter * h_raw]\n",
    "\n",
    "\t\tfor i in range(0, self.num_filter):\n",
    "\t\t\tt[i] = torch.unsqueeze(t[i], 1)\n",
    "\t\t\t# [batch * 1 * num_per_filter * h_raw]\n",
    "\t\t\tmax_ = torch.unsqueeze(torch.squeeze(self.max_t(t[i]), 1), 3)\n",
    "\t\t\tavg_ = torch.unsqueeze(torch.squeeze(self.avg_t(t[i]), 1), 3)\n",
    "\n",
    "\t\t\tattention_ = torch.cat((max_, avg_), dim=1)\n",
    "\t\t\tattention_ = self.sig(self.conv_t1[i](attention_))\n",
    "\t\t\tattention_ = torch.unsqueeze(torch.squeeze(attention_, 3), 1)\n",
    "\t\t\tt[i] = t[i] * attention_\n",
    "\t\t\tt[i] = torch.squeeze(self.max_t(t[i]))\n",
    "\t\tt = torch.cat(t, dim=1)\n",
    "\t\tt = torch.squeeze(t)\n",
    "\t\tt = F.relu(self.lin0_(t))\n",
    "\t\t###############################################################################\n",
    "\t\t# hybrid output :  #\n",
    "\t\t###############################################################################\n",
    "\t\t# out layer\n",
    "\t\t# self.lin0x_ = torch.nn.Linear(512, r_dot)\n",
    "\t\t# self.lin0t_ = torch.nn.Linear(512, r_dsm)\n",
    "        # if self.ratio != 0.5:\n",
    "\t\t#   x = F.relu(self.lin0x_(x))\n",
    "\t\t#   t = F.relu(self.lin0t_(t))\n",
    "\n",
    "\t\t# x = torch.cat((x, t), dim=1)  # 512 + 512\n",
    "\n",
    "\t\t# t = F.relu(self.lin1_(t))\n",
    "\t\tt = F.relu(self.lin2_(t))\n",
    "\t\tt = F.relu(self.lin3_(t))\n",
    "\t\tt = F.dropout(t, p=0.5, training=self.training)\n",
    "\t\tt = F.log_softmax(self.lin4_(t), dim=-1)\n",
    "\n",
    "\t\treturn t\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset_, size_):\n",
    "        for idx, data_ in enumerate(dataset_):\n",
    "            data_len_ = len(data_)\n",
    "            if data_len_ < size_[0]:\n",
    "                pad = torch.zeros(size_[0] - data_len_, size_[1])\n",
    "                dataset_[idx] = torch.cat((data_, pad), dim=0)\n",
    "            else:\n",
    "                dataset_[idx] = data_[:size_[0]]\n",
    "        self.dateset = dataset_\n",
    "        self.size = size_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dateset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dateset[idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# init model\n",
    "size_ = [175, 45]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HybridNet(size_[0], size_[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(Train_dot_loader, Train_dsm_loader):\n",
    "\tmodel.train()\n",
    "\tloss_all = 0\n",
    "\titer_loader = iter(Train_dsm_loader)\n",
    "\tfor data in Train_dot_loader:\n",
    "\t\tdata1 = next(iter_loader)\n",
    "\t\tdata1 = data1.to(device)\n",
    "\t\tdata = data.to(device)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\tx, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\t\toutput = model(x, edge_index, batch, data1)\n",
    "\t\tloss = F.nll_loss(output, data.y)\n",
    "\t\tloss.backward()\n",
    "\t\tloss_all += data.num_graphs * loss.item()\n",
    "\t\toptimizer.step()\n",
    "\treturn loss_all / len(Train_dot_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def test(loader0, loader1):\n",
    "\t# loader0:dot loader1:dsm\n",
    "\tmodel.eval()\n",
    "\tcorrect = 0\n",
    "\titer_loader = iter(loader1)\n",
    "\tfor data0 in loader0:\n",
    "\t\tdata1 = next(iter_loader)\n",
    "\t\tdata1 = data1.to(device)\n",
    "\t\tdata0 = data0.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tx, edge_index, batch = data0.x, data0.edge_index, data0.batch\n",
    "\t\ty_pred = model(x, edge_index, batch, data1)\n",
    "\t\ty_pred = y_pred.max(dim=1)[1]\n",
    "\t\tcorrect += y_pred.eq(data0.y).sum().item()\n",
    "\tacc = correct / len(loader0.dataset)\n",
    "\treturn round(acc, 6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>epoch:000===>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Miniconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:883.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train_set:0, loss:1.24869, Train_acc:0.62266\n",
      "#train_set:1, loss:0.71391, Train_acc:0.81953\n",
      "#train_set:2, loss:0.51308, Train_acc:0.87031\n",
      "#train_set:3, loss:0.42045, Train_acc:0.87500\n",
      "avg loss:0.72403\n",
      "Test_acc:0.87843\n",
      "Time span:71.20989\n",
      "===>epoch:001===>\n",
      "===>epoch:002===>\n",
      "===>epoch:003===>\n",
      "===>epoch:004===>\n",
      "#train_set:0, loss:0.14673, Train_acc:0.95586\n",
      "#train_set:1, loss:0.13558, Train_acc:0.96641\n",
      "#train_set:2, loss:0.12011, Train_acc:0.96211\n",
      "#train_set:3, loss:0.13474, Train_acc:0.95430\n",
      "avg loss:0.13429\n",
      "Test_acc:0.94550\n",
      "Time span:285.46257\n",
      "===>epoch:005===>\n",
      "===>epoch:006===>\n",
      "===>epoch:007===>\n",
      "===>epoch:008===>\n",
      "#train_set:0, loss:0.07214, Train_acc:0.97188\n",
      "#train_set:1, loss:0.06160, Train_acc:0.97383\n",
      "#train_set:2, loss:0.06987, Train_acc:0.97070\n",
      "#train_set:3, loss:0.07147, Train_acc:0.97070\n",
      "avg loss:0.06877\n",
      "Test_acc:0.95884\n",
      "Time span:499.62811\n",
      "===>epoch:009===>\n",
      "===>epoch:010===>\n",
      "===>epoch:011===>\n",
      "===>epoch:012===>\n",
      "#train_set:0, loss:0.06302, Train_acc:0.97930\n",
      "#train_set:1, loss:0.05610, Train_acc:0.98086\n",
      "#train_set:2, loss:0.04826, Train_acc:0.98281\n",
      "#train_set:3, loss:0.06436, Train_acc:0.97695\n",
      "avg loss:0.05793\n",
      "Test_acc:0.96837\n",
      "Time span:714.60833\n",
      "===>epoch:013===>\n",
      "===>epoch:014===>\n",
      "===>epoch:015===>\n",
      "===>epoch:016===>\n",
      "#train_set:0, loss:0.04650, Train_acc:0.97813\n",
      "#train_set:1, loss:0.06247, Train_acc:0.97969\n",
      "#train_set:2, loss:0.06393, Train_acc:0.98125\n",
      "#train_set:3, loss:0.04702, Train_acc:0.98203\n",
      "avg loss:0.05498\n",
      "Test_acc:0.97294\n",
      "Time span:925.31717\n",
      "===>epoch:017===>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 36\u001B[0m\n\u001B[0;32m     34\u001B[0m Train_dot_loader \u001B[38;5;241m=\u001B[39m Dataloader_dot(train_dot, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     35\u001B[0m Train_dsm_loader \u001B[38;5;241m=\u001B[39m Dataloader_dsm(MyDataset(train_dsm, size_), batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 36\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTrain_dot_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTrain_dsm_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m loss_list\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[6], line 16\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(Train_dot_loader, Train_dsm_loader)\u001B[0m\n\u001B[0;32m     14\u001B[0m \tloss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mnll_loss(output, data\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m     15\u001B[0m \tloss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 16\u001B[0m \tloss_all \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mnum_graphs \u001B[38;5;241m*\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \toptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss_all \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(Train_dot_loader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# main:\n",
    "start_time = time.time()\n",
    "\n",
    "with open(rf'D:\\Desktop\\hybrid-SVD\\dataset\\multi_test.pk', 'rb') as f_:\n",
    "\tcur_dataset = pickle.load(f_)\n",
    "\trandom.shuffle(cur_dataset)\n",
    "\ttest_dsm = []\n",
    "\ttest_dot = []\n",
    "\tfor d in cur_dataset:\n",
    "\t\ttest_dot.append(d[0])\n",
    "\t\ttest_dsm.append(d[1])\n",
    "\tdel cur_dataset\n",
    "\tgc.collect()\n",
    "\tTest_dot_loader = Dataloader_dot(test_dot, batch_size=32, shuffle=False, drop_last=True)\n",
    "\tTest_dsm_loader = Dataloader_dsm(MyDataset(test_dsm, size_), batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "best_best_model = None\n",
    "best_bset_acc = 0\n",
    "\n",
    "for epoch in range(0, 64):\n",
    "\tprint(\"===>epoch:{:03d}===>\".format(epoch))\n",
    "\tloss_list = []\n",
    "\tfor i_ in range(0, 4):\n",
    "\t\twith open(rf'D:\\Desktop\\hybrid-SVD\\dataset\\multi_train{i_}.pk', 'rb') as f_:\n",
    "\t\t\tcur_dataset = pickle.load(f_)\n",
    "\t\t\trandom.shuffle(cur_dataset)\n",
    "\t\t\ttrain_dsm = []\n",
    "\t\t\ttrain_dot = []\n",
    "\t\t\tfor d in cur_dataset:\n",
    "\t\t\t\ttrain_dot.append(d[0])\n",
    "\t\t\t\ttrain_dsm.append(d[1])\n",
    "\t\t\tdel cur_dataset\n",
    "\t\t\tgc.collect()\n",
    "\t\t\tTrain_dot_loader = Dataloader_dot(train_dot, batch_size=32, shuffle=False, drop_last=True)\n",
    "\t\t\tTrain_dsm_loader = Dataloader_dsm(MyDataset(train_dsm, size_), batch_size=32, shuffle=False, drop_last=True)\n",
    "\t\t\tloss = train(Train_dot_loader, Train_dsm_loader)\n",
    "\t\t\tloss_list.append(loss)\n",
    "\t\t\tif epoch % 4 == 0:\n",
    "\t\t\t\tacc = test(Train_dot_loader, Train_dsm_loader)\n",
    "\t\t\t\tprint(\"#train_set:{:d}, loss:{:.5f}, Train_acc:{:.5f}\".format(i_, loss, acc))\n",
    "\t\t\tif epoch % 4 == 0 and i_ == 3:\n",
    "\t\t\t\tprint(\"avg loss:{:.5f}\".format( math.fsum(loss_list) / 4))\n",
    "\n",
    "\tif epoch % 4 == 0:\n",
    "\t\tacc = test(Test_dot_loader, Test_dsm_loader)\n",
    "\t\tprint(\"Test_acc:{:.5f}\".format(acc))\n",
    "\t\tprint(\"Time span:{:.5f}\".format(time.time() - start_time))\n",
    "\n",
    "print(\"Total time span:{:.5f}\".format(time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
